# Проверка качества датасетов

Для задачи Uplift моделирования важно проверить датсет на чистоту и соотвествие некоторым критериям. В частности, к этим критериям относятся:
1. Независимость наличия целевого действия от признакого описания: p(T, X) = p(T)p(X)
2. Проверка релевантности

## Независимость T и X
Проверка на независимость данных переменных обычно проводится с помощью так называемого [Classifier Two-Sample Test (C2ST)](https://arxiv.org/pdf/1610.06545.pdf). Проверка нулевой гипотезы осуществляется с помощью классификатора, задачей которого является выявление ращличий между двумя распределениями. Классификатор обучается на некоторой тренировочной подвыборке, а затем пытается на отложенной подвыборке восстановить метку из какого распрделения были взяты данные. Если классификатор показывает точность, близкую к точности случайного угадывания, то можно сказать, и это доказывается, что выборки являются независимыми. Примечательно, что данный ответы классификатора имеют простое распределение в случае, если $H_0$ выполняется, а значит можно также посчитать p-value.

Так, в статье [A Large Scale Benchmark for Uplift Modeling](https://s3.us-east-2.amazonaws.com/criteo-uplift-dataset/large-scale-benchmark.pdf). Данный метод используется для проверки качества датасета. Однако, я не уверен, что там они использовали его правильно и p-value могут немного отличаться. В данной статье классификатору подавалсь несбалансированная выборка, что могло повлиять на праивльность теста.

## Проверка релевантности признаков
Для проверки релевантности признаков используются схожи подход, что и для проверки независимости. В данной задаче сравнивается эффективность некоторой предиктивной модели, над случайным угадыванием целевой переменной.

На данный момент я не нашёл какой-либо теоретической обоснованности данного метода, однако несмотря на это, данный метод имеет некоторую интуитивную обоснованость.


## Тесты на различие распределений 